{'accelerator': 'gpu',
 'accumulate_grad_batches': 2,
 'base_dir': '/private/workspace/yangx/data/mm/mimic-cxr-jpg/2.0.0/files/',
 'batch_size': 24,
 'beam_size': 3,
 'bert_path': '/private/workspace/yangx/data/mm/hf/bert-base-uncased',
 'chexbert_path': '/private/workspace/yangx/data/mm/hf/chexbert.pth',
 'ckpt_file': None,
 'cxr_bert_path': '/private/workspace/yangx/data/mm/hf/BiomedVLP-CXR-BERT-specialized',
 'dataset': 'mimic_cxr',
 'delta_file': None,
 'devices': 1,
 'diversity_penalty': 0,
 'do_sample': False,
 'emb_dim': 4096,
 'end_sym': '</s>',
 'every_n_train_steps': 0,
 'freeze_vm': True,
 'global_only': False,
 'gradient_clip_val': None,
 'img_encoder': 'swim',
 'learning_rate': 0.0003,
 'length_penalty': 2.0,
 'limit_test_batches': 1.0,
 'limit_train_batches': 1.0,
 'limit_val_batches': 0.5,
 'llama_model': './hf/Llama-2-7b-chat-hf',
 'llm_alpha': 64,
 'llm_r': 32,
 'llm_use_lora': False,
 'lora_dropout': 0.1,
 'loss_mode': 'sentence',
 'low_resource': False,
 'max_epochs': 2,
 'max_length': 100,
 'max_new_tokens': 150,
 'min_new_tokens': 50,
 'mn_annotation': '/private/workspace/yangx/data/mm/preprocessed/addscore/result/final_multi_view_no_long_add1score_sentence_level.json',
 'mw_annotation': '/private/workspace/yangx/data/mm/preprocessed/addscore/result/final_multi_view_with_long_add1score_sentence_level.json',
 'no_repeat_ngram_size': 2,
 'num_beam_groups': 1,
 'num_nodes': 1,
 'num_sanity_val_steps': 2,
 'num_workers': 12,
 'precision': 'bf16-mixed',
 'prefetch_factor': 4,
 'rad_dino_path': '/private/workspace/yangx/data/mm/hf/rad-dino',
 'repetition_penalty': 2.0,
 'savedmodel_path': './save/mimic_cxr/train_stage1',
 'scorer_types': ['Bleu_4', 'CIDEr'],
 'sentence_ratio': 0.75,
 'sn_annotation': '/private/workspace/yangx/data/mm/preprocessed/addscore/result/final_single_view_no_long_add1score_sentence_level.json',
 'stage_class': 1,
 'strategy': 'ddp',
 'sw_annotation': '/private/workspace/yangx/data/mm/preprocessed/addscore/result/final_single_view_with_long_add1score_sentence_level.json',
 'swintransformer_road': '',
 'temperature': 0,
 'test': False,
 'test_batch_size': 8,
 'test_mode': 'train_1',
 'val_batch_size': 4,
 'val_check_interval': 0.5,
 'validate': False,
 'vicuna_model': '/private/workspace/yangx/data/mm/hf/vicuna-7b-v1.5',
 'vision_token_number': 64,
 'visual_delta_file': None,
 'visual_token_number': 128,
 'weights': [0.5, 0.5]}
Global seed set to 42
start train
Using bfloat16 Automatic Mixed Precision (AMP)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Loading Frozen vision encoder:/private/workspace/yangx/data/mm/hf/rad-dino -- Done
/private/workspace/yangx/data/mm/env/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
Loading Frozen text encoder:/private/workspace/yangx/data/mm/hf/BiomedVLP-CXR-BERT-specialized -- Done
Loading LLAMA
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]